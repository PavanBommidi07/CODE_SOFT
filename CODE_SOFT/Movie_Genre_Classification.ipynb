{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShQdz9spH6Ko",
        "outputId": "d0dee595-bdd7-45b4-89bd-e38eeea74900"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading Train Data: 100%|██████████| 50/50 [00:00<00:00, 143.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ID                               TITLE       GENRE  \\\n",
            "0   1       Oscar et la dame rose (2009)       drama    \n",
            "1   2                       Cupid (1997)    thriller    \n",
            "2   3   Young, Wild and Wonderful (1980)       adult    \n",
            "3   4              The Secret Sin (1915)       drama    \n",
            "4   5             The Unrecovered (2007)       drama    \n",
            "\n",
            "                                         DESCRIPTION  \n",
            "0   Listening in to a conversation between his do...  \n",
            "1   A brother and sister with a past incestuous r...  \n",
            "2   As the bus empties the students for their fie...  \n",
            "3   To help their unemployed father make ends mee...  \n",
            "4   The film's title refers not only to the un-re...  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:900: UserWarning: unknown class(es) ['drama'] will be ignored\n",
            "  warnings.warn(\n",
            "Vectorizing Training Data: 100%|██████████| 50/50 [00:16<00:00,  3.12it/s]\n",
            "Training Model: 100%|██████████| 50/50 [00:01<00:00, 27.31it/s]\n",
            "Loading Test Data: 100%|██████████| 50/50 [00:01<00:00, 45.46it/s]\n",
            "Vectorizing Test Data: 100%|██████████| 50/50 [00:13<00:00,  3.62it/s]\n",
            "Predicting on Test Data: 100%|██████████| 50/50 [00:01<00:00, 31.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model evaluation results and metrics have been saved to 'model_evaluation.txt'.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Genre list for reference and fallback genre\n",
        "genre_list = ['action', 'adult', 'adventure', 'animation', 'biography', 'comedy',\n",
        "              'crime', 'documentary', 'family', 'fantasy', 'game-show', 'history',\n",
        "              'horror', 'music', 'musical', 'mystery', 'news', 'reality-tv',\n",
        "              'romance', 'sci-fi', 'short', 'sport', 'talk-show', 'thriller',\n",
        "              'war', 'western']\n",
        "fallback_genre = 'unknown'\n",
        "\n",
        "# Load and preprocess the training data\n",
        "try:\n",
        "    with tqdm(total=50, desc='Loading Train Data') as pbar:\n",
        "        train_data = pd.read_csv('/content/train_data.txt', sep=':::', header=None,\n",
        "                                 names=['ID', 'TITLE', 'GENRE', 'DESCRIPTION'], engine='python')\n",
        "        pbar.update(50)\n",
        "except Exception as e:\n",
        "    print(\"Error loading train data:\", e)\n",
        "    raise\n",
        "print(train_data.head())\n",
        "\n",
        "# Clean genre labels to remove unwanted spaces\n",
        "train_data['GENRE'] = train_data['GENRE'].str.strip().str.lower()\n",
        "X_train = train_data['DESCRIPTION'].str.lower()\n",
        "\n",
        "# Process and binarize the genre labels\n",
        "genre_labels = train_data['GENRE'].str.split(', ')\n",
        "mlb = MultiLabelBinarizer(classes=genre_list)\n",
        "y_train = mlb.fit_transform(genre_labels)\n",
        "\n",
        "# Vectorize the training data\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "with tqdm(total=50, desc='Vectorizing Training Data') as pbar:\n",
        "    X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "    pbar.update(50)\n",
        "\n",
        "# Train the model\n",
        "with tqdm(total=50, desc='Training Model') as pbar:\n",
        "    naive_bayes = MultinomialNB()\n",
        "    multi_output_classifier = MultiOutputClassifier(naive_bayes)\n",
        "    multi_output_classifier.fit(X_train_tfidf, y_train)\n",
        "    pbar.update(50)\n",
        "\n",
        "# Load the test dataset\n",
        "try:\n",
        "    with tqdm(total=50, desc=\"Loading Test Data\") as pbar:\n",
        "        test_data = pd.read_csv('/content/test_data.txt', sep=':::', header=None,\n",
        "                                names=['ID', 'TITLE', 'DESCRIPTION'], engine='python')\n",
        "        pbar.update(50)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading test_data: {e}\")\n",
        "    raise\n",
        "\n",
        "# Preprocess and vectorize the test data\n",
        "X_test = test_data['DESCRIPTION'].str.lower()\n",
        "with tqdm(total=50, desc=\"Vectorizing Test Data\") as pbar:\n",
        "    X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "    pbar.update(50)\n",
        "\n",
        "# Predict genres for the test data\n",
        "with tqdm(total=50, desc=\"Predicting on Test Data\") as pbar:\n",
        "    y_pred = multi_output_classifier.predict(X_test_tfidf)\n",
        "    pbar.update(50)\n",
        "\n",
        "# Prepare the output for test data\n",
        "test_movie_names = test_data['TITLE']\n",
        "predicted_genres = mlb.inverse_transform(y_pred)\n",
        "test_results = pd.DataFrame({'MOVIE_NAME': test_movie_names, 'PREDICTED_GENRES': predicted_genres})\n",
        "\n",
        "# Replace empty predicted genres with the fallback genre\n",
        "test_results['PREDICTED_GENRES'] = test_results['PREDICTED_GENRES'].apply(lambda genres: [fallback_genre] if not genres else genres)\n",
        "\n",
        "# Write the test results to an output file\n",
        "with open(\"/content/test_data_solution.txt\", \"w\", encoding=\"utf-8\") as output_file:\n",
        "    for _, row in test_results.iterrows():\n",
        "        movie_name = row['MOVIE_NAME']\n",
        "        genre_str = ', '.join(row['PREDICTED_GENRES'])\n",
        "        output_file.write(f\"{movie_name}::: {genre_str}\\n\")\n",
        "\n",
        "# Evaluate the model using the training data\n",
        "y_train_pred = multi_output_classifier.predict(X_train_tfidf)\n",
        "\n",
        "# Calculate and display the evaluation metrics\n",
        "accuracy = accuracy_score(y_train, y_train_pred)\n",
        "precision = precision_score(y_train, y_train_pred, average='micro', zero_division=0)\n",
        "recall = recall_score(y_train, y_train_pred, average='micro', zero_division=0)\n",
        "f1 = f1_score(y_train, y_train_pred, average='micro', zero_division=0)\n",
        "\n",
        "# Append evaluation metrics to the output file\n",
        "with open(\"model_evaluation.txt\", \"a\", encoding=\"utf-8\") as output_file:\n",
        "    output_file.write(\"\\n\\nModel Evaluation Metrics:\\n\")\n",
        "    output_file.write(f\"Accuracy: {accuracy * 100:.2f}%\\n\")\n",
        "    output_file.write(f\"Precision: {precision:.2f}\\n\")\n",
        "    output_file.write(f\"Recall: {recall:.2f}\\n\")\n",
        "    output_file.write(f\"F1-score: {f1:.2f}\\n\")\n",
        "\n",
        "print(\"Model evaluation results and metrics have been saved to 'model_evaluation.txt'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train_tfidf, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train on the split training set\n",
        "multi_output_classifier.fit(X_train_split, y_train_split)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_val_pred = multi_output_classifier.predict(X_val_split)\n",
        "\n",
        "# Calculate validation metrics\n",
        "val_accuracy = accuracy_score(y_val_split, y_val_pred)\n",
        "val_precision = precision_score(y_val_split, y_val_pred, average='micro')\n",
        "val_recall = recall_score(y_val_split, y_val_pred, average='micro')\n",
        "val_f1 = f1_score(y_val_split, y_val_pred, average='micro')\n",
        "\n",
        "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
        "print(f\"Validation Precision: {val_precision:.2f}\")\n",
        "print(f\"Validation Recall: {val_recall:.2f}\")\n",
        "print(f\"Validation F1-score: {val_f1:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PvgAxh3IyfA",
        "outputId": "15bd408b-3ea2-4ce6-d527-cf10ff5b9d8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 41.10%\n",
            "Validation Precision: 0.74\n",
            "Validation Recall: 0.23\n",
            "Validation F1-score: 0.35\n"
          ]
        }
      ]
    }
  ]
}